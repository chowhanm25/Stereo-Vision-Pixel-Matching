{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéØ Stereo Vision Pixel Matching System\n",
    "\n",
    "**Interactive Computer Vision Assignment - Epipolar Geometry Visualization**\n",
    "\n",
    "This notebook demonstrates advanced stereo vision concepts including:\n",
    "- Fundamental matrix computation using SIFT + FLANN + RANSAC\n",
    "- Interactive pixel correspondence matching\n",
    "- Real-time epipolar line visualization\n",
    "- Zero Normalized Cross Correlation (ZNCC) based matching\n",
    "\n",
    "**Instructions:**\n",
    "1. Run all cells sequentially\n",
    "2. Upload your stereo image pair when prompted\n",
    "3. Click on any pixel in the LEFT image to see correspondence\n",
    "4. Observe the epipolar line (green) and best match (+) in right image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-title"
   },
   "source": [
    "## üì¶ Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install opencv-python numpy ipywidgets ipyevents matplotlib\n",
    "\n",
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import Image as WImage, HBox\n",
    "from ipyevents import Event\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('‚úÖ All dependencies installed successfully!')\n",
    "print('üéØ Ready to start stereo vision matching!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "class-title"
   },
   "source": [
    "## üîß StereoMatcher Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stereo-matcher-class"
   },
   "outputs": [],
   "source": [
    "class StereoMatcher:\n",
    "    def __init__(self, window_size=15, search_range=50, display_scale=1.0):\n",
    "        \"\"\"\n",
    "        Initialize StereoMatcher with configurable parameters\n",
    "        \n",
    "        Args:\n",
    "            window_size (int): Size of correlation window for ZNCC\n",
    "            search_range (int): Search range along epipolar line\n",
    "            display_scale (float): Image display scaling factor\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.search_range = search_range\n",
    "        self.display_scale = display_scale\n",
    "        \n",
    "    def upload_images(self):\n",
    "        \"\"\"Upload stereo image pair from user\"\"\"\n",
    "        # Upload LEFT image\n",
    "        print(\"‚á® Upload LEFT stereo image:\")\n",
    "        up1 = files.upload()\n",
    "        clear_output()\n",
    "        fn1 = next(iter(up1))\n",
    "        img1 = cv2.imdecode(np.frombuffer(up1[fn1], np.uint8), cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Upload RIGHT image\n",
    "        print(\"‚á® Upload RIGHT stereo image:\")\n",
    "        up2 = files.upload()\n",
    "        clear_output()\n",
    "        fn2 = next(iter(up2))\n",
    "        img2 = cv2.imdecode(np.frombuffer(up2[fn2], np.uint8), cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Resize images for display if needed\n",
    "        if self.display_scale != 1.0:\n",
    "            img1 = cv2.resize(img1, (0,0), fx=self.display_scale, fy=self.display_scale, interpolation=cv2.INTER_AREA)\n",
    "            img2 = cv2.resize(img2, (0,0), fx=self.display_scale, fy=self.display_scale, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Store images and convert to grayscale\n",
    "        self.img1 = img1\n",
    "        self.gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        self.img2 = img2\n",
    "        self.gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        print(\"‚úÖ Left image loaded successfully\")\n",
    "        print(\"‚úÖ Right image loaded successfully\")\n",
    "        \n",
    "    def detect_and_match_features(self):\n",
    "        \"\"\"Detect SIFT features and match using FLANN\"\"\"\n",
    "        # SIFT feature detection\n",
    "        sift = cv2.SIFT_create()\n",
    "        k1, d1 = sift.detectAndCompute(self.gray1, None)\n",
    "        k2, d2 = sift.detectAndCompute(self.gray2, None)\n",
    "        \n",
    "        # FLANN matching\n",
    "        flann = cv2.FlannBasedMatcher({'algorithm': 1, 'trees': 5}, {'checks': 50})\n",
    "        raw = flann.knnMatch(d1, d2, k=2)\n",
    "        \n",
    "        # Lowe's ratio test\n",
    "        good = [m for m, n in raw if m.distance < 0.7 * n.distance]\n",
    "        \n",
    "        # Extract matching points\n",
    "        self.pts1 = np.float32([k1[m.queryIdx].pt for m in good])\n",
    "        self.pts2 = np.float32([k2[m.trainIdx].pt for m in good])\n",
    "        \n",
    "        print(f\"üîç Found {len(good)} good feature matches\")\n",
    "        \n",
    "    def calculate_fundamental_matrix(self):\n",
    "        \"\"\"Compute fundamental matrix using RANSAC\"\"\"\n",
    "        F, mask = cv2.findFundamentalMat(self.pts1, self.pts2, cv2.FM_RANSAC, 3.0)\n",
    "        \n",
    "        # Normalize matrix\n",
    "        self.F = F / F[2,2]\n",
    "        \n",
    "        # Keep only inliers\n",
    "        inliers = mask.ravel() == 1\n",
    "        self.pts1 = self.pts1[inliers]\n",
    "        self.pts2 = self.pts2[inliers]\n",
    "        \n",
    "        print(f\"üßÆ Fundamental matrix computed with {len(self.pts1)} inliers\")\n",
    "        print(f\"üìê F-matrix:\\n{self.F}\")\n",
    "        \n",
    "    def compute_zncc(self, A, B):\n",
    "        \"\"\"\n",
    "        Zero Normalized Cross Correlation\n",
    "        Measures similarity between two image patches\n",
    "        \"\"\"\n",
    "        A = A.astype(np.float32)\n",
    "        B = B.astype(np.float32)\n",
    "        \n",
    "        # Zero-mean normalization\n",
    "        Za, Zb = A - A.mean(), B - B.mean()\n",
    "        \n",
    "        # Correlation calculation\n",
    "        num = (Za * Zb).sum()\n",
    "        den = np.sqrt((Za*Za).sum() * (Zb*Zb).sum())\n",
    "        \n",
    "        return num/den if den > 1e-5 else -1\n",
    "        \n",
    "    def find_correspondence(self, x, y):\n",
    "        \"\"\"\n",
    "        Find best correspondence along epipolar line using ZNCC\n",
    "        \n",
    "        Args:\n",
    "            x, y: Pixel coordinates in left image\n",
    "        Returns:\n",
    "            Best match coordinates and epipolar line parameters\n",
    "        \"\"\"\n",
    "        # Compute epipolar line in right image\n",
    "        v = np.array([x, y, 1.], dtype=np.float32)\n",
    "        a, b, c = self.F.dot(v)\n",
    "        \n",
    "        # Normalize line equation\n",
    "        norm = np.hypot(a, b)\n",
    "        a, b, c = a/norm, b/norm, c/norm\n",
    "        \n",
    "        # Extract patch from left image\n",
    "        hw = self.window_size // 2\n",
    "        L = self.gray1[max(0,y-hw):y+hw+1, max(0,x-hw):x+hw+1]\n",
    "        \n",
    "        # Search along epipolar line\n",
    "        best, bx, by = -1, None, None\n",
    "        h2, w2 = self.gray2.shape\n",
    "        \n",
    "        for dx in range(-self.search_range, self.search_range+1):\n",
    "            xp = x + dx\n",
    "            if not (0 <= xp < w2):\n",
    "                continue\n",
    "                \n",
    "            yp = int(-(a*xp + c) / b)\n",
    "            if not (0 <= yp < h2):\n",
    "                continue\n",
    "                \n",
    "            # Extract patch from right image\n",
    "            R = self.gray2[max(0,yp-hw):yp+hw+1, max(0,xp-hw):xp+hw+1]\n",
    "            \n",
    "            # Compute ZNCC if patches have same size\n",
    "            if R.shape == L.shape:\n",
    "                score = self.compute_zncc(L, R)\n",
    "                if score > best:\n",
    "                    best, bx, by = score, xp, yp\n",
    "        \n",
    "        return bx, by, (a, b, c)\n",
    "        \n",
    "    def draw_epipolar_line(self, img, line):\n",
    "        \"\"\"Draw epipolar line on image\"\"\"\n",
    "        a, b, c = line\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Calculate line endpoints\n",
    "        x0, y0 = 0, int(-c/b)\n",
    "        x1, y1 = w, int(-(a*w + c)/b)\n",
    "        \n",
    "        # Draw line\n",
    "        out = img.copy()\n",
    "        cv2.line(out, (x0,y0), (x1,y1), (0,255,0), 2)\n",
    "        return out\n",
    "        \n",
    "    def interactive_matching(self):\n",
    "        \"\"\"Setup interactive display with click events\"\"\"\n",
    "        def to_png_bytes(img):\n",
    "            _, buf = cv2.imencode('.png', img)\n",
    "            return buf.tobytes()\n",
    "        \n",
    "        # Create widget images\n",
    "        wL = WImage(value=to_png_bytes(self.img1), format='png')\n",
    "        wR = WImage(value=to_png_bytes(self.img2), format='png')\n",
    "        display(HBox([wL, wR]))\n",
    "        \n",
    "        def on_click(evt):\n",
    "            x, y = int(evt['relativeX']), int(evt['relativeY'])\n",
    "            \n",
    "            # Reset images\n",
    "            wL.value = to_png_bytes(self.img1)\n",
    "            wR.value = to_png_bytes(self.img2)\n",
    "            \n",
    "            # Mark clicked point\n",
    "            C1 = self.img1.copy()\n",
    "            cv2.circle(C1, (x,y), 5, (0,0,255), -1)\n",
    "            wL.value = to_png_bytes(C1)\n",
    "            \n",
    "            # Find correspondence\n",
    "            bx, by, line = self.find_correspondence(x, y)\n",
    "            \n",
    "            # Draw epipolar line\n",
    "            R2 = self.draw_epipolar_line(self.img2, line)\n",
    "            \n",
    "            # Mark best match\n",
    "            if bx is not None:\n",
    "                cv2.drawMarker(R2, (bx,by), (0,0,255), \n",
    "                              markerType=cv2.MARKER_CROSS, \n",
    "                              markerSize=20, thickness=2)\n",
    "                print(f\"üìç Best match found at ({bx}, {by})\")\n",
    "            else:\n",
    "                print(\"‚ùå No valid match found\")\n",
    "                \n",
    "            wR.value = to_png_bytes(R2)\n",
    "        \n",
    "        # Setup click event\n",
    "        evt = Event(source=wL, watched_events=['click'])\n",
    "        evt.on_dom_event(on_click)\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Main execution pipeline\"\"\"\n",
    "        print(\"üéØ Starting Stereo Vision Pixel Matching System\")\n",
    "        print(\"" + \"="*50)\n",
    "        \n",
    "        # Step 1: Upload images\n",
    "        self.upload_images()\n",
    "        \n",
    "        # Step 2: Feature detection and matching\n",
    "        print(\"\\nüîç Detecting and matching features...\")\n",
    "        self.detect_and_match_features()\n",
    "        \n",
    "        # Step 3: Fundamental matrix computation\n",
    "        print(\"\\nüßÆ Computing fundamental matrix...\")\n",
    "        self.calculate_fundamental_matrix()\n",
    "        \n",
    "        # Step 4: Interactive matching\n",
    "        print(\"\\nüéØ Setup complete! Click anywhere on the LEFT image below:\")\n",
    "        print(\"   ‚Ä¢ Green line = epipolar line in right image\")\n",
    "        print(\"   ‚Ä¢ Red + = best matching pixel\")\n",
    "        print(\"" + \"="*50)\n",
    "        \n",
    "        self.interactive_matching()\n",
    "\n",
    "print('üîß StereoMatcher class loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-title"
   },
   "source": [
    "## üöÄ Run Interactive Stereo Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-matching"
   },
   "outputs": [],
   "source": [
    "# Initialize and run stereo matcher\n",
    "matcher = StereoMatcher(\n",
    "    window_size=15,        # Correlation window size\n",
    "    search_range=50,       # Search range along epipolar line\n",
    "    display_scale=0.5      # Scale images for display\n",
    ")\n",
    "\n",
    "# Start the interactive session\n",
    "matcher.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "customization-title"
   },
   "source": [
    "## ‚öôÔ∏è Parameter Customization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom-parameters"
   },
   "outputs": [],
   "source": [
    "# Example: Run with different parameters for better accuracy\n",
    "# Uncomment and run this cell if you want to try different settings\n",
    "\n",
    "# matcher_advanced = StereoMatcher(\n",
    "#     window_size=21,        # Larger window for smoother regions\n",
    "#     search_range=100,      # Wider search for better accuracy\n",
    "#     display_scale=0.3      # Smaller display for large images\n",
    "# )\n",
    "# \n",
    "# matcher_advanced.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "info-title"
   },
   "source": [
    "## üìñ How It Works\n",
    "\n",
    "### Algorithm Overview:\n",
    "\n",
    "1. **Feature Detection**: Uses SIFT to detect distinctive keypoints in both images\n",
    "2. **Feature Matching**: FLANN matcher finds correspondences with Lowe's ratio test\n",
    "3. **Fundamental Matrix**: RANSAC computes robust geometric relationship\n",
    "4. **Epipolar Line**: For clicked point, compute corresponding line in right image\n",
    "5. **Correlation Search**: ZNCC matching along epipolar line finds best correspondence\n",
    "6. **Visualization**: Draw epipolar line (green) and best match (+) on images\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Epipolar Constraint**: Corresponding points must lie on epipolar lines\n",
    "- **ZNCC**: Zero Normalized Cross Correlation for robust similarity matching\n",
    "- **RANSAC**: Robust estimation to handle outliers in feature matching\n",
    "- **Fundamental Matrix**: Encodes the geometric relationship between stereo views\n",
    "\n",
    "### Tips for Best Results:\n",
    "\n",
    "- Use stereo images with good texture and features\n",
    "- Ensure sufficient overlap between left and right views\n",
    "- Click on textured regions for more reliable matching\n",
    "- Adjust parameters based on your image characteristics"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}